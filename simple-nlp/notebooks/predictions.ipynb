{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the year from the abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "import string # библиотека для работы со строками\n",
    "import nltk   # Natural Language Toolkit\n",
    "# загружаем библиотеку для лемматизации\n",
    "import pymorphy2 # Морфологический анализатор\n",
    "\n",
    "#вычисляем tf-idf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import Binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_types import AuthorsDB\n",
    "from data_types import PublicationsDB\n",
    "from data_types import AbstractsDB\n",
    "\n",
    "audb = AuthorsDB()\n",
    "audb.load()\n",
    "pubdb = PublicationsDB()\n",
    "pubdb.load()\n",
    "absdb = AbstractsDB()\n",
    "absdb.load()\n",
    "\n",
    "filename = \"../data/mathnet_iam_authors_dict.pkl\"\n",
    "with open(filename,'rb') as inp:\n",
    "    authors_dict = pickle.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub = pd.DataFrame.from_dict(pubdb.db,orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to get \n",
    "- abstract and it's tokenization\n",
    "- year of paper\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = absdb.db[absdb.db['abstract'].notna()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7597 entries, vyurv213 to vmumm4420\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   abstract  5609 non-null   object\n",
      " 1   keywords  2525 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 178.1+ KB\n"
     ]
    }
   ],
   "source": [
    "absdb.db.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5609 entries, vyurv213 to da31\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   abstract  5609 non-null   object\n",
      " 1   keywords  2525 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 131.5+ KB\n"
     ]
    }
   ],
   "source": [
    "abstracts.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\-\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загружаем список стоп-слов для русского\n",
    "nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('russian')\n",
    "\n",
    "# примеры стоп-слов\n",
    "stop_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# знаки препинания\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenizer = nltk.WordPunctTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dates = [str(x) for x in np.arange(1900, 2022)]\n",
    "def process_data(data):\n",
    "    texts = []    \n",
    "    \n",
    "    # поочередно проходим по всем новостям в списке\n",
    "    for item in data:\n",
    "               \n",
    "        text_lower = item.lower() # приводим все слова к нижнему регистру\n",
    "        tokens     = word_tokenizer.tokenize(text_lower) #разбиваем екст на слова\n",
    "        \n",
    "        # удаляем пунктуацию и стоп-слова\n",
    "        # tokens = [word for word in tokens if (word not in string.punctuation and word not in stop_words and word not in dates)]\n",
    "        tokens = [word for word in tokens if (word not in string.punctuation and word not in stop_words)]\n",
    "        \n",
    "        texts.append(tokens) # добавляем в предобработанный список\n",
    "    \n",
    "    return texts\n",
    "\n",
    "def process_abstractsdb(data):\n",
    "    texts = []    \n",
    "    \n",
    "    # поочередно проходим по всем новостям в списке\n",
    "    for index,row in data.iterrows():\n",
    "        # print(row['abstract'])        \n",
    "        print(type(row['abstract']))\n",
    "        text = row['abstract']\n",
    "        if (row['keywords'] is not None):\n",
    "            # print(text)\n",
    "            # print(row['keywords'])\n",
    "            print(type(row['keywords']))\n",
    "            text += row['keywords']                   \n",
    "        text_lower = text.lower() # приводим все слова к нижнему регистру\n",
    "        tokens     = word_tokenizer.tokenize(text_lower) #разбиваем екст на слова                \n",
    "        tokens = [word for word in tokens if (word not in string.punctuation and word not in stop_words and not word.isnumeric())]\n",
    "                      \n",
    "        texts.append(tokens) # добавляем в предобработанный список\n",
    "    \n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3 entries, vyurv213 to vyurv46\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   abstract  3 non-null      object\n",
      " 1   keywords  3 non-null      object\n",
      "dtypes: object(2)\n",
      "memory usage: 72.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "abstracts.loc[['vyurv213','vyurv1','vyurv46']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "exp = [\"Теперь каждый пример представлен списком слов.\",\n",
    "       \"Причем все слова с маленькой буквы.\",\n",
    "       \"Пунктуацию и стоп-слова мы удалили.\"]\n",
    "texts_exp = process_data(exp)\n",
    "\n",
    "# texts = process_abstractsdb(abstracts.loc[['vyurv213','vyurv1','vyurv46']])\n",
    "texts = process_abstractsdb(abstracts.loc[['vyurv213','vyurv1','vyurv46']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['каждый', 'пример', 'представлен', 'списком', 'слов'], ['причем', 'слова', 'маленькой', 'буквы'], ['пунктуацию', 'стоп', 'слова', 'удалили']]\n"
     ]
    }
   ],
   "source": [
    "print(texts_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['увеличивающийся', 'рост', 'числа', 'компонент', 'суперкомпьютеров', 'приводит', 'специалистов', 'области', 'hpc', 'неблагоприятным', 'оценкам', 'будущих', 'суперкомпьютеров', 'диапазон', 'среднего', 'времени', 'отказами', 'составлять', 'часа', 'часов', 'данная', 'оценка', 'ставит', 'вопрос', 'возможность', 'проведения', 'длительных', 'расчетов', 'суперкомпьютерах', 'работе', 'предлагается', 'метод', 'восстановления', 'отказов', 'требующий', 'возврата', 'большинства', 'процессов', 'последней', 'контрольной', 'точке', 'позволить', 'сократить', 'накладные', 'расходы', 'некоторых', 'вычислительных', 'алгоритмов', 'стандартный', 'метод', 'обеспечения', 'отказоустойчивости', 'заключается', 'координированном', 'сохранении', 'случае', 'отказа', 'осуществляется', 'возврат', 'процессов', 'последней', 'контрольной', 'точке', 'предлагаемая', 'стратегия', 'заключается', 'координированном', 'сохранении', 'журналировании', 'передаваемых', 'данных', 'случае', 'отказа', 'происходит', 'асинхронное', 'восстановление', 'асинхронном', 'восстановлении', 'несколько', 'запасных', 'процессов', 'проводят', 'пересчет', 'данных', 'потерянных', 'отказа', 'остальные', 'процессы', 'находятся', 'ожидании', 'окончания', 'процедуры', 'восстановления', 'потерянных', 'данных', 'разработаны', 'параллельные', 'программы', 'решающие', 'задачу', 'распространении', 'тепла', 'тонкой', 'пластине', 'данных', 'программах', 'отказы', 'происходят', 'вызова', 'функции', 'raise', 'sigkill', '),', 'координированное', 'асинхронное', 'восстановление', 'осуществляется', 'помощью', 'функционала', 'ulfm', 'получения', 'теоретических', 'оценок', 'накладных', 'расходов', 'предложен', 'имитационный', 'метод', 'моделирующий', 'исполнение', 'программы', 'отказами', 'данном', 'методе', 'отказ', 'произойти', 'время', 'расчетов', 'также', 'время', 'сохранения', 'контрольных', 'точек', 'ходе', 'восстановления', 'проведено', 'сравнение', 'методов', 'восстановления', 'разных', 'значениях', 'частоты', 'отказов', 'задачи', 'распространения', 'тепла', 'тонкой', 'пластине', 'которой', 'объем', 'данных', 'журналирования', 'незначителен', 'сравнение', 'показало', 'применение', 'асинхронного', 'восстановления', 'приводит', 'сокращению', 'накладных', 'расходов', 'теоретической', 'оценке', 'вычислительном', 'эксперименте', 'расширение', 'ulfm', 'контрольные', 'точки', 'координированное', 'сохранение', 'асинхронное', 'восстановление', 'отказоустойчивость'], ['рассматривается', 'проблема', 'выполнения', 'длительных', 'расчетов', 'высокопроизводительных', 'вычислительных', 'системах', 'компоненты', 'которых', 'подвержены', 'отказам', 'программ', 'запускаемых', 'подобных', 'системах', 'существенным', 'является', 'возможность', 'обработки', 'отказов', 'путем', 'автоматического', 'продолжения', 'расчета', 'оставшихся', 'работоспособных', 'узлах', 'системы', 'возможность', 'обработки', 'отказов', 'предусматривается', 'разрабатываемом', 'стандарте', 'mpi', 'работе', 'кратко', 'описывается', 'библиотека', 'моделирования', 'отказов', 'тестирования', 'отказоустойчивых', 'алгоритмов', 'использующих', 'функционал', 'разрабатываемого', 'стандарта', 'mpi', 'описана', 'техника', 'отказоустойчивости', 'примере', 'тестовой', 'задачи', 'проведено', 'сравение', 'записи', 'контрольных', 'точек', 'оперативную', 'память', 'распределенную', 'файловую', 'систему', 'параллельные', 'вычисления', 'отказоустойчивость', 'контрольные', 'точки', 'mpi', 'ulfm', 'моделирование', 'отказов'], ['рассматриваются', 'вопросы', 'связанные', 'проведением', 'расчетов', 'распределенных', 'вычислительных', 'системах', 'компоненты', 'которых', 'подвержены', 'отказам', 'работе', 'приводятся', 'определения', 'системы', 'сбоя', 'ошибки', 'отказа', 'модели', 'сбоя', 'наиболее', 'важные', 'результаты', 'исследований', 'отказов', 'параллельных', 'вычислительных', 'системах', 'числе', 'большими', 'группами', 'дисков', 'основные', 'существующие', 'методы', 'восстановления', 'распространенные', 'программные', 'реализации', 'обеспечения', 'отказоустойчивости', 'развивается', 'подход', 'обеспечения', 'отказоустойчивости', 'уровне', 'пользователя', 'данный', 'подход', 'требует', 'непосредственного', 'участия', 'разработчика', 'прикладной', 'программы', 'реализации', 'метода', 'обеспечения', 'отказоустойчивости', 'частности', 'формировании', 'контрольных', 'точек', 'процедур', 'восстановления', 'предложена', 'схема', 'сохранения', 'памяти', 'вычислительных', 'узлов', 'данных', 'прикладной', 'программы', 'формирующих', 'согласованную', 'глобальную', 'контрольную', 'точку', 'её', 'рамках', 'осуществляется', 'дублирование', 'локальных', 'контрольных', 'точек', 'позволяет', 'восстановить', 'вычислительный', 'процесс', 'число', 'отказов', 'превосходит', 'допустимого', 'данной', 'схемы', 'уровня', 'использована', 'различных', 'протоколах', 'восстановления', 'модификациях', 'параллельные', 'вычисления', 'отказоустойчивость', 'контрольные', 'точки', 'mpi']]\n"
     ]
    }
   ],
   "source": [
    "print(texts)\n",
    "texts_ll = texts[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализируем лемматизатор :)\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходное слово: рассматриваются \tЛемматизированное: рассматриваться\n",
      "Исходное слово: вопросы \tЛемматизированное: вопрос\n",
      "Исходное слово: связанные \tЛемматизированное: связанный\n",
      "Исходное слово: проведением \tЛемматизированное: проведение\n",
      "Исходное слово: расчетов \tЛемматизированное: расчёт\n",
      "Исходное слово: распределенных \tЛемматизированное: распределённый\n",
      "Исходное слово: вычислительных \tЛемматизированное: вычислительный\n",
      "Исходное слово: системах \tЛемматизированное: система\n",
      "Исходное слово: компоненты \tЛемматизированное: компонент\n",
      "Исходное слово: которых \tЛемматизированное: который\n",
      "Исходное слово: подвержены \tЛемматизированное: подверженный\n",
      "Исходное слово: отказам \tЛемматизированное: отказ\n",
      "Исходное слово: работе \tЛемматизированное: работа\n",
      "Исходное слово: приводятся \tЛемматизированное: приводиться\n",
      "Исходное слово: определения \tЛемматизированное: определение\n",
      "Исходное слово: системы \tЛемматизированное: система\n",
      "Исходное слово: сбоя \tЛемматизированное: сбой\n",
      "Исходное слово: ошибки \tЛемматизированное: ошибка\n",
      "Исходное слово: отказа \tЛемматизированное: отказ\n",
      "Исходное слово: модели \tЛемматизированное: модель\n",
      "Исходное слово: сбоя \tЛемматизированное: сбой\n",
      "Исходное слово: наиболее \tЛемматизированное: наиболее\n",
      "Исходное слово: важные \tЛемматизированное: важный\n",
      "Исходное слово: результаты \tЛемматизированное: результат\n",
      "Исходное слово: исследований \tЛемматизированное: исследование\n",
      "Исходное слово: отказов \tЛемматизированное: отказ\n",
      "Исходное слово: параллельных \tЛемматизированное: параллельный\n",
      "Исходное слово: вычислительных \tЛемматизированное: вычислительный\n",
      "Исходное слово: системах \tЛемматизированное: система\n",
      "Исходное слово: числе \tЛемматизированное: число\n",
      "Исходное слово: большими \tЛемматизированное: больший\n",
      "Исходное слово: группами \tЛемматизированное: группа\n",
      "Исходное слово: дисков \tЛемматизированное: диск\n",
      "Исходное слово: основные \tЛемматизированное: основной\n",
      "Исходное слово: существующие \tЛемматизированное: существующий\n",
      "Исходное слово: методы \tЛемматизированное: метод\n",
      "Исходное слово: восстановления \tЛемматизированное: восстановление\n",
      "Исходное слово: распространенные \tЛемматизированное: распространить\n",
      "Исходное слово: программные \tЛемматизированное: программный\n",
      "Исходное слово: реализации \tЛемматизированное: реализация\n",
      "Исходное слово: обеспечения \tЛемматизированное: обеспечение\n",
      "Исходное слово: отказоустойчивости \tЛемматизированное: отказоустойчивость\n",
      "Исходное слово: развивается \tЛемматизированное: развиваться\n",
      "Исходное слово: подход \tЛемматизированное: подход\n",
      "Исходное слово: обеспечения \tЛемматизированное: обеспечение\n",
      "Исходное слово: отказоустойчивости \tЛемматизированное: отказоустойчивость\n",
      "Исходное слово: уровне \tЛемматизированное: уровень\n",
      "Исходное слово: пользователя \tЛемматизированное: пользователь\n",
      "Исходное слово: данный \tЛемматизированное: данный\n",
      "Исходное слово: подход \tЛемматизированное: подход\n",
      "Исходное слово: требует \tЛемматизированное: требовать\n",
      "Исходное слово: непосредственного \tЛемматизированное: непосредственный\n",
      "Исходное слово: участия \tЛемматизированное: участие\n",
      "Исходное слово: разработчика \tЛемматизированное: разработчик\n",
      "Исходное слово: прикладной \tЛемматизированное: прикладной\n",
      "Исходное слово: программы \tЛемматизированное: программа\n",
      "Исходное слово: реализации \tЛемматизированное: реализация\n",
      "Исходное слово: метода \tЛемматизированное: метод\n",
      "Исходное слово: обеспечения \tЛемматизированное: обеспечение\n",
      "Исходное слово: отказоустойчивости \tЛемматизированное: отказоустойчивость\n",
      "Исходное слово: частности \tЛемматизированное: частность\n",
      "Исходное слово: формировании \tЛемматизированное: формирование\n",
      "Исходное слово: контрольных \tЛемматизированное: контрольный\n",
      "Исходное слово: точек \tЛемматизированное: точка\n",
      "Исходное слово: процедур \tЛемматизированное: процедура\n",
      "Исходное слово: восстановления \tЛемматизированное: восстановление\n",
      "Исходное слово: предложена \tЛемматизированное: предложить\n",
      "Исходное слово: схема \tЛемматизированное: схема\n",
      "Исходное слово: сохранения \tЛемматизированное: сохранение\n",
      "Исходное слово: памяти \tЛемматизированное: память\n",
      "Исходное слово: вычислительных \tЛемматизированное: вычислительный\n",
      "Исходное слово: узлов \tЛемматизированное: узел\n",
      "Исходное слово: данных \tЛемматизированное: данные\n",
      "Исходное слово: прикладной \tЛемматизированное: прикладной\n",
      "Исходное слово: программы \tЛемматизированное: программа\n",
      "Исходное слово: формирующих \tЛемматизированное: формировать\n",
      "Исходное слово: согласованную \tЛемматизированное: согласовать\n",
      "Исходное слово: глобальную \tЛемматизированное: глобальный\n",
      "Исходное слово: контрольную \tЛемматизированное: контрольный\n",
      "Исходное слово: точку \tЛемматизированное: точка\n",
      "Исходное слово: её \tЛемматизированное: её\n",
      "Исходное слово: рамках \tЛемматизированное: рамка\n",
      "Исходное слово: осуществляется \tЛемматизированное: осуществляться\n",
      "Исходное слово: дублирование \tЛемматизированное: дублирование\n",
      "Исходное слово: локальных \tЛемматизированное: локальный\n",
      "Исходное слово: контрольных \tЛемматизированное: контрольный\n",
      "Исходное слово: точек \tЛемматизированное: точка\n",
      "Исходное слово: позволяет \tЛемматизированное: позволять\n",
      "Исходное слово: восстановить \tЛемматизированное: восстановить\n",
      "Исходное слово: вычислительный \tЛемматизированное: вычислительный\n",
      "Исходное слово: процесс \tЛемматизированное: процесс\n",
      "Исходное слово: число \tЛемматизированное: число\n",
      "Исходное слово: отказов \tЛемматизированное: отказ\n",
      "Исходное слово: превосходит \tЛемматизированное: превосходить\n",
      "Исходное слово: допустимого \tЛемматизированное: допустимый\n",
      "Исходное слово: данной \tЛемматизированное: дать\n",
      "Исходное слово: схемы \tЛемматизированное: схема\n",
      "Исходное слово: уровня \tЛемматизированное: уровень\n",
      "Исходное слово: использована \tЛемматизированное: использовать\n",
      "Исходное слово: различных \tЛемматизированное: различный\n",
      "Исходное слово: протоколах \tЛемматизированное: протокол\n",
      "Исходное слово: восстановления \tЛемматизированное: восстановление\n",
      "Исходное слово: модификациях \tЛемматизированное: модификация\n",
      "Исходное слово: параллельные \tЛемматизированное: параллельный\n",
      "Исходное слово: вычисления \tЛемматизированное: вычисление\n",
      "Исходное слово: отказоустойчивость \tЛемматизированное: отказоустойчивость\n",
      "Исходное слово: контрольные \tЛемматизированное: контрольный\n",
      "Исходное слово: точки \tЛемматизированное: точка\n",
      "Исходное слово: mpi \tЛемматизированное: mpi\n"
     ]
    }
   ],
   "source": [
    "for aword in texts[2]:\n",
    "    aword_norm = morph.parse(aword)[0].normal_form\n",
    "    print(\"Исходное слово: %s \\tЛемматизированное: %s\" % (aword, aword_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ebc9a398d0d4b18836aeee7a22e3447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# применяем лемматизацию ко всем текстам\n",
    "print(range(len(texts)))\n",
    "\n",
    "for i in tqdm(range(len(texts))):           # tqdm_notebook создает шкалу прогресса :)\n",
    "    text_lemmatized = [morph.parse(x)[0].normal_form for x in texts[i]] # применяем лемматизацию для каждого слова в тексте\n",
    "    texts[i] = ' '.join(text_lemmatized)\n",
    "    # time.sleep(1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['увеличиваться рост число компонент суперкомпьютер приводить специалист область hpc неблагоприятный оценка будущий суперкомпьютер диапазон среднее время отказ составлять час час дать оценка ставить вопрос возможность проведение длительный расчёт суперкомпьютер работа предлагаться метод восстановление отказ требовать возврат большинство процесс последний контрольный точка позволить сократить накладный расход некоторый вычислительный алгоритм стандартный метод обеспечение отказоустойчивость заключаться координировать сохранение случай отказ осуществляться возврат процесс последний контрольный точка предлагать стратегия заключаться координировать сохранение журналирование передаваемый данные случай отказ происходить асинхронный восстановление асинхронный восстановление несколько запасный процесс проводить пересчёт данные потерянный отказ остальной процесс находиться ожидание окончание процедура восстановление потерянный данные разработать параллельный программа решающий задача распространение тепло тонкий пластина данные программа отказ происходить вызов функция raise sigkill ), координировать асинхронный восстановление осуществляться помощь функционал ulfm получение теоретический оценка накладный расход предложный имитационный метод моделирующий исполнение программа отказ данный метод отказ произойти время расчёт также время сохранение контрольный точка ход восстановление провести сравнение метод восстановление разный значение частота отказ задача распространение тепло тонкий пластина который объём данные журналирование незначительный сравнение показать применение асинхронный восстановление приводить сокращение накладный расход теоретический оценка вычислительный эксперимент расширение ulfm контрольный точка координировать сохранение асинхронный восстановление отказоустойчивость', 'рассматриваться проблема выполнение длительный расчёт высокопроизводительный вычислительный система компонент который подверженный отказ программа запускать подобный система существенный являться возможность обработка отказ путём автоматический продолжение расчёт остаться работоспособный узел система возможность обработка отказ предусматриваться разрабатывать стандарт mpi работа кратко описываться библиотека моделирование отказ тестирование отказоустойчивый алгоритм использовать функционал разрабатывать стандарт mpi описать техника отказоустойчивость пример тестовый задача провести сравение запись контрольный точка оперативный память распределённый файловый система параллельный вычисление отказоустойчивость контрольный точка mpi ulfm моделирование отказ', 'рассматриваться вопрос связанный проведение расчёт распределённый вычислительный система компонент который подверженный отказ работа приводиться определение система сбой ошибка отказ модель сбой наиболее важный результат исследование отказ параллельный вычислительный система число больший группа диск основной существующий метод восстановление распространить программный реализация обеспечение отказоустойчивость развиваться подход обеспечение отказоустойчивость уровень пользователь данный подход требовать непосредственный участие разработчик прикладной программа реализация метод обеспечение отказоустойчивость частность формирование контрольный точка процедура восстановление предложить схема сохранение память вычислительный узел данные прикладной программа формировать согласовать глобальный контрольный точка её рамка осуществляться дублирование локальный контрольный точка позволять восстановить вычислительный процесс число отказ превосходить допустимый дать схема уровень использовать различный протокол восстановление модификация параллельный вычисление отказоустойчивость контрольный точка mpi']\n"
     ]
    }
   ],
   "source": [
    "print(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/46118910/scikit-learn-vectorizer-max-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(smooth_idf=1, sublinear_tf=1, token_pattern=&#x27;\\\\w{2,}&#x27;,\n",
       "                use_idf=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(smooth_idf=1, sublinear_tf=1, token_pattern=&#x27;\\\\w{2,}&#x27;,\n",
       "                use_idf=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(smooth_idf=1, sublinear_tf=1, token_pattern='\\\\w{2,}',\n",
       "                use_idf=1)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit TF-IDF on train texts\n",
    "# vectorizer = TfidfVectorizer(min_df=1,   max_features=None, strip_accents='unicode',  analyzer='word',token_pattern=r'\\w{2,}',ngram_range=(1, 2), use_idf=1,smooth_idf=1,sublinear_tf=1)\n",
    "vectorizer = TfidfVectorizer(min_df=1,   max_features=None, analyzer='word',token_pattern=r'\\w{2,}', use_idf=1,smooth_idf=1,sublinear_tf=1) \n",
    "vectorizer.fit(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\n"
     ]
    }
   ],
   "source": [
    "print(len(vectorizer.get_feature_names_out()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hpc', 'mpi', 'raise', 'sigkill', 'ulfm', 'автоматический',\n",
       "       'алгоритм', 'асинхронный', 'библиотека', 'больший', 'большинство',\n",
       "       'будущий', 'важный', 'возврат', 'возможность', 'вопрос',\n",
       "       'восстановить', 'восстановление', 'время', 'вызов', 'выполнение',\n",
       "       'высокопроизводительный', 'вычисление', 'вычислительный',\n",
       "       'глобальный', 'группа', 'данные', 'данный', 'дать', 'диапазон',\n",
       "       'диск', 'длительный', 'допустимый', 'дублирование', 'её',\n",
       "       'журналирование', 'задача', 'заключаться', 'запасный', 'запись',\n",
       "       'запускать', 'значение', 'имитационный', 'исполнение',\n",
       "       'использовать', 'исследование', 'компонент', 'контрольный',\n",
       "       'координировать', 'который', 'кратко', 'локальный', 'метод',\n",
       "       'моделирование', 'моделирующий', 'модель', 'модификация',\n",
       "       'наиболее', 'накладный', 'находиться', 'неблагоприятный',\n",
       "       'незначительный', 'некоторый', 'непосредственный', 'несколько',\n",
       "       'обеспечение', 'область', 'обработка', 'объём', 'ожидание',\n",
       "       'окончание', 'оперативный', 'описать', 'описываться',\n",
       "       'определение', 'основной', 'остальной', 'остаться',\n",
       "       'осуществляться', 'отказ', 'отказоустойчивость',\n",
       "       'отказоустойчивый', 'оценка', 'ошибка', 'память', 'параллельный',\n",
       "       'передаваемый', 'пересчёт', 'пластина', 'подверженный', 'подобный',\n",
       "       'подход', 'позволить', 'позволять', 'показать', 'получение',\n",
       "       'пользователь', 'помощь', 'последний', 'потерянный',\n",
       "       'превосходить', 'предлагать', 'предлагаться', 'предложить',\n",
       "       'предложный', 'предусматриваться', 'приводить', 'приводиться',\n",
       "       'прикладной', 'применение', 'пример', 'проблема', 'проведение',\n",
       "       'провести', 'проводить', 'программа', 'программный', 'продолжение',\n",
       "       'произойти', 'происходить', 'протокол', 'процедура', 'процесс',\n",
       "       'путём', 'работа', 'работоспособный', 'развиваться', 'различный',\n",
       "       'разный', 'разрабатывать', 'разработать', 'разработчик', 'рамка',\n",
       "       'распределённый', 'распространение', 'распространить',\n",
       "       'рассматриваться', 'расход', 'расчёт', 'расширение', 'реализация',\n",
       "       'результат', 'решающий', 'рост', 'сбой', 'связанный', 'система',\n",
       "       'случай', 'согласовать', 'сократить', 'сокращение', 'составлять',\n",
       "       'сохранение', 'специалист', 'сравение', 'сравнение', 'среднее',\n",
       "       'ставить', 'стандарт', 'стандартный', 'стратегия',\n",
       "       'суперкомпьютер', 'существенный', 'существующий', 'схема', 'также',\n",
       "       'теоретический', 'тепло', 'тестирование', 'тестовый', 'техника',\n",
       "       'тонкий', 'точка', 'требовать', 'увеличиваться', 'узел', 'уровень',\n",
       "       'участие', 'файловый', 'формирование', 'формировать', 'функционал',\n",
       "       'функция', 'ход', 'час', 'частность', 'частота', 'число',\n",
       "       'эксперимент', 'являться'], dtype=object)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Топ-10 слов\n",
    "vectorizer.get_feature_names_out()[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = vectorizer.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 190)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_vectorizer(data,status):\n",
    "    filename = '../data/vectorizer.pkl'    \n",
    "    if status == 'write':        \n",
    "        with open(filename,'wb') as outp:\n",
    "            pickle.dump(data, outp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_vectorizer(vectorizer,status=\"write\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectorizer():\n",
    "    filename = '../data/vectorizer.pkl'\n",
    "    res = None    \n",
    "    with open(filename,'rb') as inp:\n",
    "        res = pickle.load(inp)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = load_vectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hpc', 'mpi', 'raise', 'sigkill', 'ulfm', 'автоматический',\n",
       "       'алгоритм', 'асинхронный', 'библиотека', 'больший'], dtype=object)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x.get_feature_names_out()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importance of the article for Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# freq   = CountVectorizer()\n",
    "# corpus = freq.fit_transform(corpus)\n",
    "# X =['причём стоп слово удалить буква'] \n",
    "request =['суперкомпьютерное моделирование отказоустойчивых вычислений на hpc системах'] \n",
    "train_y = vectorizer.transform(X)\n",
    "\n",
    "onehot = Binarizer()\n",
    "ohe_request = onehot.fit_transform(train_y.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(corpus)\n",
    "# print(type(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 190)\n",
      "(3, 190)\n"
     ]
    }
   ],
   "source": [
    "print(ohe_request.shape)\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.        ]\n",
      " [0.21686795]\n",
      " [0.        ]]\n"
     ]
    }
   ],
   "source": [
    "answer= train_X.dot(ohe_request.T)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = answer.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 0]\n"
     ]
    }
   ],
   "source": [
    "pubs_index = np.argsort(answer)[::-1][:5]\n",
    "print(pubs_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vyurv1', 'vyurv46', 'vyurv213']\n"
     ]
    }
   ],
   "source": [
    "req_pups = list(absdb.db.iloc[pubs_index].index)\n",
    "print(req_pups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21686795, 0.        , 0.        ])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer[pubs_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pub.info()\n",
    "pub.loc[req_pups];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def get_authors_rating(df, coef):\n",
    "    # print(df)\n",
    "    # print(type(df))\n",
    "    # print(coef)\n",
    "    # print(type(coef))\n",
    "    rating = defaultdict(int)\n",
    "    for index in range(len(df)):\n",
    "        # print(f'index = {index}, row = {df.iloc[index]}')        \n",
    "        for author in df.iloc[index]['author_id']:  \n",
    "            # print(index)          \n",
    "            print(f'add coef = {coef[index]} to author = {author}')\n",
    "            rating[author] += coef[index]            \n",
    "            print(rating)\n",
    "    return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add coef = 0.21686794707455037 to author = 113970\n",
      "defaultdict(<class 'int'>, {'113970': 0.21686794707455037})\n",
      "add coef = 0.21686794707455037 to author = 22428\n",
      "defaultdict(<class 'int'>, {'113970': 0.21686794707455037, '22428': 0.21686794707455037})\n",
      "add coef = 0.0 to author = 113970\n",
      "defaultdict(<class 'int'>, {'113970': 0.21686794707455037, '22428': 0.21686794707455037})\n",
      "add coef = 0.0 to author = 22428\n",
      "defaultdict(<class 'int'>, {'113970': 0.21686794707455037, '22428': 0.21686794707455037})\n",
      "add coef = 0.0 to author = 113970\n",
      "defaultdict(<class 'int'>, {'113970': 0.21686794707455037, '22428': 0.21686794707455037})\n",
      "add coef = 0.0 to author = 148811\n",
      "defaultdict(<class 'int'>, {'113970': 0.21686794707455037, '22428': 0.21686794707455037, '148811': 0.0})\n",
      "add coef = 0.0 to author = 22428\n",
      "defaultdict(<class 'int'>, {'113970': 0.21686794707455037, '22428': 0.21686794707455037, '148811': 0.0})\n",
      "defaultdict(<class 'int'>, {'113970': 0.21686794707455037, '22428': 0.21686794707455037, '148811': 0.0})\n"
     ]
    }
   ],
   "source": [
    "res = get_authors_rating(pub.loc[req_pups],answer[pubs_index])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X.todense()[2,[20, 19, 18, 15, 13,  9,  0]].sum()\n",
    "# train_X.todense()[2,[20, 19, 18, 15, 13,  9,  0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "58602d8dccd692fa32abd17425fd5d45fcdd50ad23d8d4cc69f0d11e0a82e605"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('mynetscrap': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
