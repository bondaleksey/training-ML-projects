{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterating through the list of authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from parsing_page import parsing_author_page, parsing_article_page\n",
    "import time\n",
    "import requests\n",
    "from os.path import exists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../data/mathnet_iam_authors_dict.pkl\"\n",
    "with open(filename,'rb') as inp:\n",
    "    authors_list = pickle.load(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main functions for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def need_to_scrap(author):\n",
    "    # interesting_list = [\"Поляков\", \"Бондаренко\"]\n",
    "    interesting_list = [\"Бондаренко\"]\n",
    "    for person in interesting_list:\n",
    "        if person in author['name']:\n",
    "            return True\n",
    "    return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author_info(mnid):\n",
    "    #need to check if we already read it\n",
    "    if mnid == \"113970\":\n",
    "        filename = \"../data/mathnet_bondarenko_page.pkl\"\n",
    "        with open(filename,'rb') as inp:\n",
    "            author_page = pickle.load(inp)\n",
    "    else:\n",
    "        print(f\"we need to request page for author mnid = {mnid}\")\n",
    "        # page_link = f\"http://www.mathnet.ru/php/person.phtml?option_lang=rus&personid={mnid}\"\n",
    "        # \n",
    "        # Chancge 'User-Agent' HEADERRRRR after some time of use !!!!\n",
    "        # headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "        # # page_link =\"http://mi.mathnet.ru/+ {}\"\n",
    "        # time.sleep(0.7)\n",
    "        # response = requests.get(page_link, headers=headers, timeout=None)\n",
    "        # if response == 200:\n",
    "        #     author_page = response.content\n",
    "        # author_page\n",
    "        return None\n",
    "    \n",
    "    soup = BeautifulSoup(author_page, 'html.parser')\n",
    "    # TODO:\n",
    "    # Need to check if this is real page and not for bot response\n",
    "    return parsing_author_page(soup) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pub_info(mnlink, status=\"testing\"):\n",
    "    print(\"../data/\" + mnlink + \".pkl\")\n",
    "    print(exists(\"../data/\" + mnlink + \".pkl\"))\n",
    "    if exists(\"../data/\" + mnlink + \".pkl\"):\n",
    "        print(\"We read from file\")\n",
    "        filename = \"../data/\" + mnlink + \".pkl\"\n",
    "        with open(filename,'rb') as inp:\n",
    "            pub_page = pickle.load(inp)\n",
    "    else:\n",
    "        \n",
    "    # if mnlink == \"vyurv213\":\n",
    "    #     filename = \"../data/one_article_example.pkl\"\n",
    "    #     with open(filename,'rb') as inp:\n",
    "    #         pub_page = pickle.load(inp)\n",
    "    # else:\n",
    "        print(f\"we need to request page for pub_page mnlink = {mnlink}\")\n",
    "        page_link = \"http://mi.mathnet.ru/\" + mnlink\n",
    "        print(page_link)\n",
    "        # Chancge 'User-Agent' HEADERRRRR after some time of use !!!!\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "        # \n",
    "        time.sleep(0.5)\n",
    "        response = requests.get(page_link, headers=headers, timeout=None)\n",
    "        # response = 403\n",
    "        print(response)\n",
    "        print(type(response))\n",
    "        if response.status_code == 200:\n",
    "            pub_page = response.content\n",
    "            # if not exists(\"../data/\" + au_item['mn_link'] + \".pkl\"):\n",
    "            print(\"we save file: \" + mnlink)\n",
    "            save_html(pub_page,mnlink)\n",
    "        else:\n",
    "            print(response.status_code)\n",
    "            print(type(response.status_code))\n",
    "            print(\"response.status_code != 200:\")\n",
    "            return None\n",
    "        # pub_page        \n",
    "    soup = BeautifulSoup(pub_page, 'html.parser')\n",
    "    if status == \"testing\":\n",
    "        return parsing_article_page(soup)\n",
    "    \n",
    "    return parsing_article_page(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_html(data, name):\n",
    "    filename = \"../data/\" + name + \".pkl\"\n",
    "    with open(filename,'wb') as outp:\n",
    "        pickle.dump(data, outp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expression expected after dictionary key and ':' (206157351.py, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [7]\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"doi\":,\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expression expected after dictionary key and ':'\n"
     ]
    }
   ],
   "source": [
    "new_author_info = {\n",
    "        \"articles_mn\":[],\n",
    "        \"coauthers\":set()\n",
    "        }\n",
    "author_db = {\n",
    "    \"mn_id\":{\n",
    "        \"articles\":\"list of mn_links\",\n",
    "        \"year\":\"list of years\",\n",
    "        \"coauthers\": \"set of mn_links\",\n",
    "        \n",
    "        },    \n",
    "}\n",
    "pub_db={\n",
    "    \"mn_link\":{\n",
    "        \"info\":\"str\",\n",
    "        \"doi\":,\n",
    "        \"udk\":,\n",
    "        \n",
    "            \n",
    "    }\n",
    "}\n",
    "abstract_db={\n",
    "    \"mn_link\":{\n",
    "        \"authors_id\":\"list\"\n",
    "        \"key_words\":\"str\"\n",
    "        \"abstracts\":\"\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def update_new_author_info(new_author_info, au, pub):    \n",
    "    \n",
    "    return new_author_info\n",
    "\n",
    "def update_authors_db(author_bd, au_db,au_new_info):\n",
    "    if au_new_info(\"mn_link\") in au_db:\n",
    "        pass\n",
    "\n",
    "def update_pub_db(au, pub):\n",
    "    pass\n",
    "                    \n",
    "def update_abstract_db(au, pub):\n",
    "    pass\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[]\n",
      "[]\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "from data_types import Author\n",
    "bond = Author()\n",
    "bond.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Бондаренко Алексей Алексеевич', 'mn_id': '113970'}\n",
      "1 {'name': 'А.А.Бондаренко, П.А.Ляхов, М.В.Якобовский, “Координированное сохранение с журналированием передаваемых данных и асинхронное восстановление в случае отказа”, Вестн. ЮУрГУ. Сер. Выч. матем. информ., 8:2 (2019), 76–91', 'mn_link': 'vyurv213', 'elib_id': '38073495'}\n",
      "../data/vyurv213.pkl\n",
      "True\n",
      "We read from file\n",
      "author_names\n",
      "['А.\\xa0А.\\xa0Бондаренко', 'П.\\xa0А.\\xa0Ляхов', 'М.\\xa0В.\\xa0Якобовский']\n",
      "author_id\n",
      "['113970', '148811', '22428']\n",
      "abstract\n",
      "Увеличивающийся рост числа компонент суперкомпьютеров приводит специалистов в области HPC к неблагоприятным оценкам для будущих суперкомпьютеров: диапазон среднего времени между отказами будет составлять от 1 часа до 9 часов. Данная оценка ставит под вопрос возможность проведения длительных расчетов на суперкомпьютерах. В работе предлагается метод восстановления после отказов, не требующий возврата большинства процессов к последней контрольной точке, что может позволить сократить накладные расходы для некоторых вычислительных алгоритмов. Стандартный метод обеспечения отказоустойчивости заключается в координированном сохранении, а в случае отказа осуществляется возврат всех процессов к последней контрольной точке. Предлагаемая стратегия заключается в координированном сохранении и журналировании передаваемых данных, а в случае отказа происходит асинхронное восстановление. При асинхронном восстановлении несколько запасных процессов проводят пересчет данных потерянных после отказа, а остальные процессы находятся в ожидании окончания процедуры восстановления потерянных данных. Разработаны параллельные программы решающие задачу о распространении тепла в тонкой пластине. В данных программах отказы происходят после вызова функции raise (SIGKILL), а координированное или асинхронное восстановление осуществляется с помощью функционала ULFM. Для получения теоретических оценок накладных расходов предложен имитационный метод, моделирующий исполнение программы с отказами. В данном методе отказ может произойти во время расчетов, а также во время сохранения контрольных точек или в ходе восстановления. Проведено сравнение методов восстановления при разных значениях частоты отказов для задачи распространения тепла в тонкой пластине, в которой объем данных для журналирования незначителен. Сравнение показало, что применение асинхронного восстановления приводит к сокращению накладных расходов от 22 % до 40 % при теоретической оценке и от 13 % до 53 % в вычислительном эксперименте.\n",
      "keywords\n",
      "расширение ULFM, контрольные точки, координированное сохранение, асинхронное восстановление, отказоустойчивость. \n",
      "doi\n",
      "10.14529/cmse190205\n",
      "udk\n",
      "004.052.3Поступила в редакцию: 20.11.2018\n",
      "reference\n",
      "А.А.Бондаренко, П.А.Ляхов, М.В.Якобовский, “Координированное сохранение с журналированием передаваемых данных и асинхронное восстановление в случае отказа”, Вестн. ЮУрГУ. Сер. Выч. матем. информ., 8:2 (2019), 76–91\n",
      "2 {'name': 'А.А.Бондаренко, М.В.Якобовский, “Моделирование отказов в высокопроизводительных вычислительных системах в рамках стандарта MPI и его расширения ULFM”, Вестн. ЮУрГУ. Сер. Выч. матем. информ., 4:3 (2015), 5–12', 'mn_link': 'vyurv1', 'elib_id': '23790220'}\n",
      "../data/vyurv1.pkl\n",
      "True\n",
      "We read from file\n",
      "author_names\n",
      "['А.\\xa0А.\\xa0Бондаренко', 'М.\\xa0В.\\xa0Якобовский']\n",
      "author_id\n",
      "['113970', '22428']\n",
      "abstract\n",
      "Рассматривается проблема выполнения длительных расчетов на высокопроизводительных вычислительных системах, компоненты которых подвержены отказам. Для программ, запускаемых на подобных системах, существенным является возможность обработки отказов путем автоматического продолжения расчета на оставшихся работоспособных узлах системы. Возможность обработки отказов предусматривается в разрабатываемом стандарте MPI 3.1. В работе кратко описывается библиотека моделирования отказов для тестирования отказоустойчивых алгоритмов, использующих функционал разрабатываемого стандарта MPI 3.1. Описана техника отказоустойчивости на примере тестовой задачи. Проведено сравение записи контрольных точек в оперативную память и в распределенную файловую систему.\n",
      "keywords\n",
      "параллельные вычисления, отказоустойчивость, контрольные точки, MPI, ULFM, моделирование отказов. \n",
      "doi\n",
      "10.14529/cmse150301\n",
      "udk\n",
      "004.052.3Поступила в редакцию: 13.04.2015\n",
      "reference\n",
      "А.А.Бондаренко, М.В.Якобовский, “Моделирование отказов в высокопроизводительных вычислительных системах в рамках стандарта MPI и его расширения ULFM”, Вестн. ЮУрГУ. Сер. Выч. матем. информ., 4:3 (2015), 5–12\n",
      "3 {'name': 'А.А.Бондаренко, М.В.Якобовский, “Обеспечение отказоустойчивости высокопроизводительных вычислений с помощью локальных контрольных точек”, Вестн. ЮУрГУ. Сер. Выч. матем. информ., 3:3 (2014), 20–36', 'mn_link': 'vyurv46'}\n",
      "../data/vyurv46.pkl\n",
      "True\n",
      "We read from file\n",
      "author_names\n",
      "['А.\\xa0А.\\xa0Бондаренко', 'М.\\xa0В.\\xa0Якобовский']\n",
      "author_id\n",
      "['113970', '22428']\n",
      "abstract\n",
      "Рассматриваются вопросы, связанные с проведением расчетов в распределенных вычислительных системах, компоненты которых подвержены отказам. В работе приводятся: определения системы, сбоя, ошибки, отказа и модели сбоя; наиболее важные результаты исследований отказов в параллельных вычислительных системах, в том числе с большими группами дисков; основные существующие методы восстановления и распространенные программные реализации обеспечения отказоустойчивости. Развивается подход обеспечения отказоустойчивости на уровне пользователя. Данный подход требует непосредственного участия разработчика прикладной программы в реализации метода обеспечения отказоустойчивости, в частности в формировании контрольных точек и процедур восстановления. Предложена схема сохранения в памяти вычислительных узлов данных прикладной программы, формирующих согласованную глобальную контрольную точку. В её рамках осуществляется дублирование локальных контрольных точек, что позволяет восстановить вычислительный процесс, если число отказов не превосходит допустимого для данной схемы уровня. Она может быть использована в различных протоколах восстановления и их модификациях.\n",
      "keywords\n",
      "параллельные вычисления, отказоустойчивость, контрольные точки, MPI. \n",
      "doi\n",
      "None\n",
      "udk\n",
      "004.052.3Поступила в редакцию: 05.08.2014\n",
      "reference\n",
      "А.А.Бондаренко, М.В.Якобовский, “Обеспечение отказоустойчивости высокопроизводительных вычислений с помощью локальных контрольных точек”, Вестн. ЮУрГУ. Сер. Выч. матем. информ., 3:3 (2014), 20–36\n",
      "113970\n",
      "['vyurv213', 'vyurv1', 'vyurv46']\n",
      "['2019', '2015', '2014']\n",
      "{'22428', '148811'}\n",
      "{'113970': {'links': ['vyurv213', 'vyurv1', 'vyurv46'], 'years': ['2019', '2015', '2014'], 'coathors': {'22428', '148811'}}}\n",
      "{'113970': {'links': ['vyurv213', 'vyurv1', 'vyurv46'], 'years': ['2019', '2015', '2014'], 'coathors': {'22428', '148811'}}}\n",
      "id 113970 not in self.db.keys()\n",
      "printing AuthorsDB:\n",
      "ind = 113970\n",
      "item = {'links': ['vyurv213', 'vyurv1', 'vyurv46'], 'years': ['2019', '2015', '2014'], 'coathors': {'22428', '148811'}}\n"
     ]
    }
   ],
   "source": [
    "from data_types import Author, AuthorsDB\n",
    "audb = AuthorsDB()\n",
    "for indx, item in authors_list.items(): \n",
    "    \n",
    "    if need_to_scrap(item):                \n",
    "        new_author = Author(item[\"mn_id\"])\n",
    "        print(item)\n",
    "        # get through pubs list on author page\n",
    "        author_pubs = get_author_info(item[\"mn_id\"])\n",
    "        for pubs_indx, pubs_item in author_pubs.items():\n",
    "            print(pubs_indx, pubs_item)\n",
    "            \n",
    "            if pubs_item[\"mn_link\"] is not None:                                \n",
    "                pub_page_info = get_pub_info(pubs_item[\"mn_link\"])                \n",
    "                \n",
    "                if pub_page_info is not None:\n",
    "                    new_author.update_author_info(pubs_item, pub_page_info)\n",
    "                    # update_pub_db(pubs_item,pub_page_info )\n",
    "                    # update_abstract_db(pubs_item,pub_page_info )\n",
    "                    for page_indx, page_item  in pub_page_info.items():\n",
    "                        print(page_indx)\n",
    "                        print(page_item)                      \n",
    "        new_author.show()\n",
    "        print(new_author.convert2dict())\n",
    "        audb.update_data(new_author.convert2dict())\n",
    "        audb.show()\n",
    "                        \n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing AuthorsDB functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond = {'007':\n",
    "    {'links': ['vyurv213', 'vyurv1', 'vyurv46'],\n",
    "     'years': ['2019', '2015', '2014'],\n",
    "     'coathors': {'148811', '22428'}}}\n",
    "my_new_inf = {'113970':\n",
    "    {'links': ['vyurv213', 'vyurv1', 'vyurv46','cool_paper'],\n",
    "     'years': ['2019', '2015', '2014','cool_year'],\n",
    "     'coathors': {'148811', '22428','009'}}}\n",
    "bond_new_inf = {'007':\n",
    "    {'links': ['mit'],\n",
    "     'years': ['1955'],\n",
    "     'coathors': {'005'}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing AuthorsDB:\n",
      "<class 'dict'>\n",
      "ind = 113970\n",
      "item = {'links': ['vyurv213', 'vyurv1', 'vyurv46'], 'years': ['2019', '2015', '2014'], 'coathors': {'148811', '22428'}}\n",
      "id 007 not in self.db.keys()\n",
      "printing AuthorsDB:\n",
      "<class 'dict'>\n",
      "ind = 113970\n",
      "item = {'links': ['vyurv213', 'vyurv1', 'vyurv46'], 'years': ['2019', '2015', '2014'], 'coathors': {'148811', '22428'}}\n",
      "ind = 007\n",
      "item = {'links': ['vyurv213', 'vyurv1', 'vyurv46'], 'years': ['2019', '2015', '2014'], 'coathors': {'148811', '22428'}}\n",
      "id 113970 in self.db.keys()\n",
      "Two info data are not equal \n",
      "{'links': ['vyurv213', 'vyurv1', 'vyurv46'], 'years': ['2019', '2015', '2014'], 'coathors': {'148811', '22428'}}\n",
      "{'links': ['vyurv213', 'vyurv1', 'vyurv46', 'cool_paper'], 'years': ['2019', '2015', '2014', 'cool_year'], 'coathors': {'148811', '009', '22428'}}\n",
      "printing AuthorsDB:\n",
      "<class 'dict'>\n",
      "ind = 113970\n",
      "item = {'links': ['vyurv213', 'vyurv1', 'vyurv46', 'cool_paper'], 'years': ['2019', '2015', '2014', 'cool_year'], 'coathors': {'148811', '009', '22428'}}\n",
      "ind = 007\n",
      "item = {'links': ['vyurv213', 'vyurv1', 'vyurv46'], 'years': ['2019', '2015', '2014'], 'coathors': {'148811', '22428'}}\n",
      "id 007 in self.db.keys()\n",
      "Two info data are not equal \n",
      "{'links': ['vyurv213', 'vyurv1', 'vyurv46'], 'years': ['2019', '2015', '2014'], 'coathors': {'148811', '22428'}}\n",
      "{'links': ['mit'], 'years': ['1955'], 'coathors': {'005'}}\n",
      "printing AuthorsDB:\n",
      "<class 'dict'>\n",
      "ind = 113970\n",
      "item = {'links': ['vyurv213', 'vyurv1', 'vyurv46', 'cool_paper'], 'years': ['2019', '2015', '2014', 'cool_year'], 'coathors': {'148811', '009', '22428'}}\n",
      "ind = 007\n",
      "item = {'links': ['vyurv213', 'vyurv1', 'vyurv46', 'mit'], 'years': ['2019', '2015', '2014', '1955'], 'coathors': {'005', '148811', '22428'}}\n"
     ]
    }
   ],
   "source": [
    "audb.show()\n",
    "audb.update_data(bond)\n",
    "audb.show()\n",
    "audb.update_data(my_new_inf)\n",
    "audb.show()\n",
    "audb.update_data(bond_new_inf)\n",
    "audb.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond2 = {'008':\n",
    "    {'links': ['vyurv213', 'vyurv1', 'vyurv46'],\n",
    "     'years': ['2019', None, '2014'],\n",
    "     'coathors': {'148811', '22428'}}}\n",
    "bond2_new_inf = {'008':\n",
    "    {'links': ['mit'],\n",
    "     'years': [None],\n",
    "     'coathors': {'005'}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing AuthorsDB:\n",
      "<class 'dict'>\n",
      "ind = 113970\n",
      "item = {'links': ['vyurv213', 'vyurv1', 'vyurv46', 'cool_paper'], 'years': ['2019', '2015', '2014', 'cool_year'], 'coathors': {'148811', '009', '22428'}}\n",
      "ind = 007\n",
      "item = {'links': ['vyurv213', 'vyurv1', 'vyurv46', 'mit'], 'years': ['2019', '2015', '2014', '1955'], 'coathors': {'005', '148811', '22428'}}\n",
      "id 008 not in self.db.keys()\n",
      "printing AuthorsDB:\n",
      "<class 'dict'>\n",
      "ind = 113970\n",
      "item = {'links': ['vyurv213', 'vyurv1', 'vyurv46', 'cool_paper'], 'years': ['2019', '2015', '2014', 'cool_year'], 'coathors': {'148811', '009', '22428'}}\n",
      "ind = 007\n",
      "item = {'links': ['vyurv213', 'vyurv1', 'vyurv46', 'mit'], 'years': ['2019', '2015', '2014', '1955'], 'coathors': {'005', '148811', '22428'}}\n",
      "ind = 008\n",
      "item = {'links': ['vyurv213', 'vyurv1', 'vyurv46'], 'years': ['2019', None, '2014'], 'coathors': {'148811', '22428'}}\n",
      "id 008 in self.db.keys()\n",
      "Two info data are not equal \n",
      "{'links': ['vyurv213', 'vyurv1', 'vyurv46'], 'years': ['2019', None, '2014'], 'coathors': {'148811', '22428'}}\n",
      "{'links': ['mit'], 'years': [None], 'coathors': {'005'}}\n",
      "printing AuthorsDB:\n",
      "<class 'dict'>\n",
      "ind = 113970\n",
      "item = {'links': ['vyurv213', 'vyurv1', 'vyurv46', 'cool_paper'], 'years': ['2019', '2015', '2014', 'cool_year'], 'coathors': {'148811', '009', '22428'}}\n",
      "ind = 007\n",
      "item = {'links': ['vyurv213', 'vyurv1', 'vyurv46', 'mit'], 'years': ['2019', '2015', '2014', '1955'], 'coathors': {'005', '148811', '22428'}}\n",
      "ind = 008\n",
      "item = {'links': ['vyurv213', 'vyurv1', 'vyurv46', 'mit'], 'years': ['2019', None, '2014', None], 'coathors': {'005', '148811', '22428'}}\n"
     ]
    }
   ],
   "source": [
    "audb.show()\n",
    "audb.update_data(bond2)\n",
    "audb.show()\n",
    "audb.update_data(bond2_new_inf)\n",
    "audb.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "audb.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing AuthorsDB:\n",
      "ind = 113970\n",
      "item = {'links': ['vyurv213', 'vyurv1', 'vyurv46'], 'years': ['2019', '2015', '2014'], 'coathors': {'22428', '148811'}}\n"
     ]
    }
   ],
   "source": [
    "new_db = AuthorsDB()\n",
    "new_db.load()\n",
    "new_db.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None not in a\n"
     ]
    }
   ],
   "source": [
    "a = [\"asd\",\"asd\",[\"asd\",\"asd\"]]\n",
    "if None in a:\n",
    "    print(\"None in a\")\n",
    "else:\n",
    "    print(\"None not in a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values(['a', 'b', 'c', None])\n",
      "None in myd.values()\n"
     ]
    }
   ],
   "source": [
    "myd = {1:\"a\",\n",
    "       2:\"b\",\n",
    "       3:\"c\",\n",
    "       4: None}\n",
    "print(myd.values())\n",
    "if None in myd.values():\n",
    "    print(\"None in myd.values()\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fa2d0ea9b172f022316cb609cfb938e35a451551785805986d1caa06569fb15e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('mynetscrap': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
